{
  "base_config": [
    {
      "name": "global_seed",
      "abbreviation": "gs",
      "description": "Set the random number seed for the experiment.",
      "type": "int",
      "default": 42
    },
    {
      "name": "val_split_ratio",
      "abbreviation": "vsr",
      "description": "Ratio to split validate dataset if it is not explicitly given.",
      "type": "float",
      "default": 0.2
    },
    {
      "name": "val_split_mode",
      "abbreviation": "vsm",
      "description": "Mode of auto splitting training and validation dataset, choose from `outside_traj` and `inside_traj`. `outside_traj` means the split is happened outside the trajectories, one trajectory can only be in one dataset. `inside_traj` means the split is happened inside the trajectories, former part of one trajectory is in training set, later part is in validation set.",
      "type": "str",
      "default": "outside_traj"
    },
    {
      "name": "ignore_check",
      "abbreviation": "igc",
      "description": "Flag to ignore data related check, force training.",
      "type": "bool",
      "default": false
    },
    {
      "name": "venv_rollout_horizon",
      "abbreviation": "vrh",
      "description": "Length of sampled trajectory, validate only if the algorithm works on sequential data.",
      "type": "int",
      "default": 14
    },
    {
      "name": "venv_gpus_per_worker",
      "abbreviation": "vgpw",
      "description": "Number of gpus per worker in venv training, small than 1 means launch multiple workers on the same gpu.",
      "type": "float",
      "default": 1.0
    },
    {
      "name": "venv_metric",
      "description": "Metric used to evaluate the trained venv, choose from `nll`, `mae`, `mse`, `wdist`.",
      "type": "str",
      "default": "wdist"
    },
    {
      "name": "venv_algo",
      "description": "Algorithm used in venv training. There are currently two algorithms to choose from, `revive` and `bc`.",
      "type": "str",
      "default": "revive"
    },
    {
      "name": "policy_gpus_per_worker",
      "abbreviation": "pgpw",
      "description": "Number of gpus per worker in venv training, small than 1 means launch multiple workers on the same gpu.",
      "type": "float",
      "default": 1.0
    },
    {
      "name": "test_horizon",
      "abbreviation": "th",
      "description": "Rollout length of the venv test.",
      "type": "int",
      "default": 14
    },
    {
      "name": "train_venv_trials",
      "abbreviation": "tvt",
      "description": "Number of total trails searched by the search algorithm in venv training.",
      "type": "int",
      "default": 10
    },
    {
      "name": "train_policy_trials",
      "abbreviation": "tpt",
      "description": "Number of total trails searched by the search algorithm in policy training.",
      "type": "int",
      "default": 10
    },
    {
      "name": "save_start_epoch",
      "abbreviation": "sse",
      "description": "We only save models after this epoch, default is 0 which means we save models from the beginning.",
      "type": "int",
      "default": 10,
      "tune": false
    }
  ],
  "venv_algo_config": {
    "revive": [
      {
        "name": "bc_epoch",
        "description": "Number of epcoh for the training process",
        "abbreviation": "bep",
        "type": "int",
        "default": 10
      },
      {
        "name": "bc_batch_size",
        "description": "Batch size of training process.",
        "abbreviation": "bbs",
        "type": "int",
        "default": 256
      },
      {
        "name": "revive_batch_size",
        "description": "Batch size of training process.",
        "abbreviation": "mbs",
        "type": "int",
        "default": 1024
      },
      {
        "name": "revive_epoch",
        "description": "Number of epcoh for the training process",
        "abbreviation": "mep",
        "type": "int",
        "default": 5000
      },
      {
        "name": "policy_hidden_features",
        "description": "Number of neurons per layer of the policy network.",
        "abbreviation": "phf",
        "type": "int",
        "default": 256
      },
      {
        "name": "policy_hidden_layers",
        "description": "Depth of policy network.",
        "abbreviation": "phl",
        "type": "int",
        "default": 5
      },
      {
        "name": "policy_backbone",
        "description": "Backbone of policy network.",
        "abbreviation": "pb",
        "type": "str",
        "default": "res"
      },
      {
        "name": "transition_hidden_features",
        "description": "Number of neurons per layer of the transition network.",
        "abbreviation": "thf",
        "type": "int",
        "default": 256
      },
      {
        "name": "transition_hidden_layers",
        "abbreviation": "thl",
        "type": "int",
        "default": 5
      },
      {
        "name": "transition_backbone",
        "description": "Backbone of Transition network.",
        "abbreviation": "tb",
        "type": "str",
        "default": "res"
      },
      {
        "name": "matcher_hidden_features",
        "description": "Number of neurons per layer of the matcher network.",
        "abbreviation": "dhf",
        "type": "int",
        "default": 256
      },
      {
        "name": "matcher_hidden_layers",
        "description": "Depth of the matcher network.",
        "abbreviation": "dhl",
        "type": "int",
        "default": 5
      },
      {
        "name": "g_steps",
        "description": "The number of update rounds of the generator in each epoch.",
        "type": "int",
        "default": 1,
        "search_mode": "grid",
        "search_values": [
          1,
          2,
          4
        ]
      },
      {
        "name": "d_steps",
        "description": "Number of update rounds of matcher in each epoch.",
        "type": "int",
        "default": 1,
        "search_mode": "grid",
        "search_values": [
          1,
          2,
          4
        ]
      },
      {
        "name": "g_lr",
        "description": "Initial learning rate of the generator.",
        "type": "float",
        "default": 4e-05,
        "search_mode": "continuous",
        "search_values": [
          1e-06,
          1e-05
        ]
      },
      {
        "name": "d_lr",
        "description": "Initial learning rate of the matcher.",
        "type": "float",
        "default": 0.0006,
        "search_mode": "continuous",
        "search_values": [
          1e-06,
          0.0001
        ]
      }
    ],
    "bc": [
      {
        "name": "bc_batch_size",
        "description": "Batch size of training process.",
        "abbreviation": "bbs",
        "type": "int",
        "default": 256
      },
      {
        "name": "bc_epoch",
        "description": "Number of epcoh for the training process",
        "abbreviation": "bep",
        "type": "int",
        "default": 500
      },
      {
        "name": "policy_hidden_features",
        "description": "Number of neurons per layer of the policy network.",
        "abbreviation": "phf",
        "type": "int",
        "default": 256
      },
      {
        "name": "policy_hidden_layers",
        "description": "Depth of policy network.",
        "abbreviation": "phl",
        "type": "int",
        "default": 4,
        "search_mode": "grid",
        "search_values": [
          3,
          4,
          5
        ]
      },
      {
        "name": "policy_backbone",
        "description": "Backbone of policy network.",
        "abbreviation": "pb",
        "type": "str",
        "default": "res",
        "search_mode": "grid",
        "search_values": [
          "mlp",
          "res"
        ]
      },
      {
        "name": "g_lr",
        "description": "Initial learning rate of the training process.",
        "type": "float",
        "default": 0.0001,
        "search_mode": "continuous",
        "search_values": [
          1e-06,
          0.001
        ]
      },
      {
        "name": "loss_type",
        "description": "Bc support different loss function(\"log_prob\", \"mae\", \"mse\").",
        "type": "str",
        "default": "log_prob"
      }
    ]
  },
  "policy_algo_config": {
    "ppo": [
      {
        "name": "ppo_batch_size",
        "description": "Batch size of training process.",
        "abbreviation": "pbs",
        "type": "int",
        "default": 256
      },
      {
        "name": "ppo_epoch",
        "description": "Number of epcoh for the training process",
        "abbreviation": "bep",
        "type": "int",
        "default": 200
      },
      {
        "name": "policy_hidden_features",
        "description": "Number of neurons per layer of the policy network.",
        "abbreviation": "phf",
        "type": "int",
        "default": 256
      },
      {
        "name": "policy_hidden_layers",
        "description": "Depth of policy network.",
        "abbreviation": "phl",
        "type": "int",
        "default": 4
      },
      {
        "name": "policy_backbone",
        "description": "Backbone of policy network.",
        "abbreviation": "pb",
        "type": "str",
        "default": "mlp"
      },
      {
        "name": "g_lr",
        "description": "Initial learning rate of the training process.",
        "type": "float",
        "default": 4e-05,
        "search_mode": "continuous",
        "search_values": [
          1e-06,
          0.001
        ]
      }
    ],
    "sac": [
      {
        "name": "sac_batch_size",
        "description": "Batch size of training process.",
        "abbreviation": "pbs",
        "type": "int",
        "default": 1024
      },
      {
        "name": "sac_epoch",
        "description": "Number of epcoh for the training process.",
        "abbreviation": "bep",
        "type": "int",
        "default": 200
      },
      {
        "name": "sac_steps_per_epoch",
        "description": "The number of update rounds of sac in each epoch.",
        "abbreviation": "sspe",
        "type": "int",
        "default": 200
      },
      {
        "name": "policy_hidden_features",
        "description": "Number of neurons per layer of the policy network.",
        "abbreviation": "phf",
        "type": "int",
        "default": 256
      },
      {
        "name": "policy_hidden_layers",
        "description": "Depth of policy network.",
        "abbreviation": "phl",
        "type": "int",
        "default": 4
      },
      {
        "name": "policy_backbone",
        "description": "Backbone of policy network.",
        "abbreviation": "pb",
        "type": "str",
        "default": "mlp"
      },
      {
        "name": "buffer_size",
        "description": "Size of the buffer to store data.",
        "abbreviation": "bfs",
        "type": "int",
        "default": 1000000.0
      },
      {
        "name": "g_lr",
        "description": "Initial learning rate of the training process.",
        "type": "float",
        "default": 4e-05,
        "search_mode": "continuous",
        "search_values": [
          1e-06,
          0.001
        ]
      }
    ]
  }
}